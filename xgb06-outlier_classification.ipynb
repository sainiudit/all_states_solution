{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started\n",
      "\n",
      "('Analyzing Column:', 'cat1')\n",
      "('Analyzing Column:', 'cat2')\n",
      "('Analyzing Column:', 'cat3')\n",
      "('Analyzing Column:', 'cat4')\n",
      "('Analyzing Column:', 'cat5')\n",
      "('Analyzing Column:', 'cat6')\n",
      "('Analyzing Column:', 'cat7')\n",
      "('Analyzing Column:', 'cat8')\n",
      "('Analyzing Column:', 'cat9')\n",
      "('Analyzing Column:', 'cat10')\n",
      "('Analyzing Column:', 'cat11')\n",
      "('Analyzing Column:', 'cat12')\n",
      "('Analyzing Column:', 'cat13')\n",
      "('Analyzing Column:', 'cat14')\n",
      "('Analyzing Column:', 'cat15')\n",
      "('Analyzing Column:', 'cat16')\n",
      "('Analyzing Column:', 'cat17')\n",
      "('Analyzing Column:', 'cat18')\n",
      "('Analyzing Column:', 'cat19')\n",
      "('Analyzing Column:', 'cat20')\n",
      "('Analyzing Column:', 'cat21')\n",
      "('Analyzing Column:', 'cat22')\n",
      "('Analyzing Column:', 'cat23')\n",
      "('Analyzing Column:', 'cat24')\n",
      "('Analyzing Column:', 'cat25')\n",
      "('Analyzing Column:', 'cat26')\n",
      "('Analyzing Column:', 'cat27')\n",
      "('Analyzing Column:', 'cat28')\n",
      "('Analyzing Column:', 'cat29')\n",
      "('Analyzing Column:', 'cat30')\n",
      "('Analyzing Column:', 'cat31')\n",
      "('Analyzing Column:', 'cat32')\n",
      "('Analyzing Column:', 'cat33')\n",
      "('Analyzing Column:', 'cat34')\n",
      "('Analyzing Column:', 'cat35')\n",
      "('Analyzing Column:', 'cat36')\n",
      "('Analyzing Column:', 'cat37')\n",
      "('Analyzing Column:', 'cat38')\n",
      "('Analyzing Column:', 'cat39')\n",
      "('Analyzing Column:', 'cat40')\n",
      "('Analyzing Column:', 'cat41')\n",
      "('Analyzing Column:', 'cat42')\n",
      "('Analyzing Column:', 'cat43')\n",
      "('Analyzing Column:', 'cat44')\n",
      "('Analyzing Column:', 'cat45')\n",
      "('Analyzing Column:', 'cat46')\n",
      "('Analyzing Column:', 'cat47')\n",
      "('Analyzing Column:', 'cat48')\n",
      "('Analyzing Column:', 'cat49')\n",
      "('Analyzing Column:', 'cat50')\n",
      "('Analyzing Column:', 'cat51')\n",
      "('Analyzing Column:', 'cat52')\n",
      "('Analyzing Column:', 'cat53')\n",
      "('Analyzing Column:', 'cat54')\n",
      "('Analyzing Column:', 'cat55')\n",
      "('Analyzing Column:', 'cat56')\n",
      "('Analyzing Column:', 'cat57')\n",
      "('Analyzing Column:', 'cat58')\n",
      "('Analyzing Column:', 'cat59')\n",
      "('Analyzing Column:', 'cat60')\n",
      "('Analyzing Column:', 'cat61')\n",
      "('Analyzing Column:', 'cat62')\n",
      "('Analyzing Column:', 'cat63')\n",
      "('Analyzing Column:', 'cat64')\n",
      "('Analyzing Column:', 'cat65')\n",
      "('Analyzing Column:', 'cat66')\n",
      "('Analyzing Column:', 'cat67')\n",
      "('Analyzing Column:', 'cat68')\n",
      "('Analyzing Column:', 'cat69')\n",
      "('Analyzing Column:', 'cat70')\n",
      "('Analyzing Column:', 'cat71')\n",
      "('Analyzing Column:', 'cat72')\n",
      "('Analyzing Column:', 'cat73')\n",
      "('Analyzing Column:', 'cat74')\n",
      "('Analyzing Column:', 'cat75')\n",
      "('Analyzing Column:', 'cat76')\n",
      "('Analyzing Column:', 'cat77')\n",
      "('Analyzing Column:', 'cat78')\n",
      "('Analyzing Column:', 'cat79')\n",
      "('Analyzing Column:', 'cat80')\n",
      "('Analyzing Column:', 'cat81')\n",
      "('Analyzing Column:', 'cat82')\n",
      "('Analyzing Column:', 'cat83')\n",
      "('Analyzing Column:', 'cat84')\n",
      "('Analyzing Column:', 'cat85')\n",
      "('Analyzing Column:', 'cat86')\n",
      "('Analyzing Column:', 'cat87')\n",
      "('Analyzing Column:', 'cat88')\n",
      "('Analyzing Column:', 'cat89')\n",
      "('Analyzing Column:', 'cat90')\n",
      "('Analyzing Column:', 'cat91')\n",
      "('Analyzing Column:', 'cat92')\n",
      "('Analyzing Column:', 'cat93')\n",
      "('Analyzing Column:', 'cat94')\n",
      "('Analyzing Column:', 'cat95')\n",
      "('Analyzing Column:', 'cat96')\n",
      "('Analyzing Column:', 'cat97')\n",
      "('Analyzing Column:', 'cat98')\n",
      "('Analyzing Column:', 'cat99')\n",
      "('Analyzing Column:', 'cat100')\n",
      "('Analyzing Column:', 'cat101')\n",
      "('Analyzing Column:', 'cat102')\n",
      "('Analyzing Column:', 'cat103')\n",
      "('Analyzing Column:', 'cat104')\n",
      "('Analyzing Column:', 'cat105')\n",
      "('Analyzing Column:', 'cat106')\n",
      "('Analyzing Column:', 'cat107')\n",
      "('Analyzing Column:', 'cat108')\n",
      "('Analyzing Column:', 'cat109')\n",
      "('Analyzing Column:', 'cat110')\n",
      "('Analyzing Column:', 'cat111')\n",
      "('Analyzing Column:', 'cat112')\n",
      "('Analyzing Column:', 'cat113')\n",
      "('Analyzing Column:', 'cat114')\n",
      "('Analyzing Column:', 'cat115')\n",
      "('Analyzing Column:', 'cat116')\n",
      "        cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10   ...    \\\n",
      "0          1     2     1     2     1     1     1     1     2      1   ...     \n",
      "1          1     2     1     1     1     1     1     1     2      2   ...     \n",
      "2          1     2     1     1     2     1     1     1     2      2   ...     \n",
      "3          2     2     1     2     1     1     1     1     2      1   ...     \n",
      "4          1     2     1     2     1     1     1     1     2      2   ...     \n",
      "5          1     2     1     1     1     1     1     1     2      1   ...     \n",
      "6          1     1     1     1     2     1     1     1     1      1   ...     \n",
      "7          1     2     1     2     1     1     1     1     2      1   ...     \n",
      "8          1     2     2     2     2     1     1     1     2      2   ...     \n",
      "9          1     2     1     1     2     2     1     1     2      1   ...     \n",
      "10         1     2     1     1     1     1     1     1     2      2   ...     \n",
      "11         1     2     1     1     2     1     1     1     2      2   ...     \n",
      "12         2     1     1     1     2     1     1     1     1      1   ...     \n",
      "13         2     1     1     1     2     2     1     1     1      1   ...     \n",
      "14         1     1     1     1     2     1     1     1     1      1   ...     \n",
      "15         1     1     1     1     2     2     1     1     1      1   ...     \n",
      "16         1     2     2     1     1     1     1     1     2      2   ...     \n",
      "17         1     1     1     1     1     2     1     1     1      1   ...     \n",
      "18         1     1     2     1     1     2     1     1     1      1   ...     \n",
      "19         1     1     1     2     1     1     1     1     1      1   ...     \n",
      "20         2     2     1     2     1     1     1     1     2      1   ...     \n",
      "21         1     1     1     2     1     2     1     1     1      1   ...     \n",
      "22         2     1     1     1     2     2     1     1     1      1   ...     \n",
      "23         2     1     1     2     1     1     1     1     1      1   ...     \n",
      "24         2     1     1     1     1     1     1     1     1      1   ...     \n",
      "25         1     1     1     2     1     1     1     1     1      1   ...     \n",
      "26         1     1     1     1     1     2     1     1     1      1   ...     \n",
      "27         2     1     1     2     1     1     1     1     1      1   ...     \n",
      "28         1     2     1     2     1     2     1     1     2      1   ...     \n",
      "29         1     1     1     1     2     1     1     1     1      1   ...     \n",
      "...      ...   ...   ...   ...   ...   ...   ...   ...   ...    ...   ...     \n",
      "313834     1     2     1     1     1     1     1     2     2      1   ...     \n",
      "313835     1     2     1     2     2     1     1     1     2      2   ...     \n",
      "313836     1     2     1     1     2     1     1     1     2      1   ...     \n",
      "313837     2     1     1     1     1     2     1     1     1      1   ...     \n",
      "313838     2     2     1     1     1     1     1     1     2      2   ...     \n",
      "313839     1     1     1     1     1     2     1     1     1      1   ...     \n",
      "313840     1     1     1     1     1     2     1     1     1      1   ...     \n",
      "313841     1     2     1     1     1     2     1     1     2      1   ...     \n",
      "313842     1     1     1     1     1     2     1     1     1      1   ...     \n",
      "313843     1     1     1     1     2     1     1     1     1      1   ...     \n",
      "313844     1     1     1     1     1     2     1     1     1      1   ...     \n",
      "313845     1     1     1     2     2     1     1     1     1      1   ...     \n",
      "313846     1     1     1     1     1     2     1     1     1      1   ...     \n",
      "313847     1     1     2     1     1     1     1     1     1      1   ...     \n",
      "313848     1     2     1     1     2     1     1     1     2      1   ...     \n",
      "313849     1     2     1     1     1     1     1     1     2      1   ...     \n",
      "313850     1     1     1     2     2     1     2     1     1      1   ...     \n",
      "313851     1     1     1     2     1     1     1     1     1      1   ...     \n",
      "313852     1     2     1     1     2     1     1     1     2      1   ...     \n",
      "313853     2     1     1     1     2     2     1     1     1      1   ...     \n",
      "313854     2     1     1     1     2     1     1     1     1      1   ...     \n",
      "313855     1     1     1     2     1     1     1     1     1      1   ...     \n",
      "313856     1     2     1     1     2     1     1     1     2      1   ...     \n",
      "313857     1     1     1     2     1     1     1     1     1      1   ...     \n",
      "313858     1     1     2     1     1     2     1     1     1      1   ...     \n",
      "313859     1     1     1     2     1     1     1     1     1      1   ...     \n",
      "313860     1     1     1     1     2     2     1     2     1      1   ...     \n",
      "313861     2     2     1     1     2     1     1     1     2      2   ...     \n",
      "313862     1     1     1     1     1     2     1     2     1      1   ...     \n",
      "313863     1     2     1     1     1     1     1     1     2      1   ...     \n",
      "\n",
      "        cat107  cat108  cat109  cat110  cat111  cat112  cat113  cat114  \\\n",
      "0           10       7      73      55       3      45      19       1   \n",
      "1           11      11      61      95       1      48      65       1   \n",
      "2            6       1      28     115       1       3      32       1   \n",
      "3           11      11      61      97       3      14      31       1   \n",
      "4            7       2       8       3       3      25      65       1   \n",
      "5            6       2      61      97       1      45      31       1   \n",
      "6            6       2      61     115       1      10      32       1   \n",
      "7            9       7      61     132       7      34      25       1   \n",
      "8           13      11      61      55       3      11      50       1   \n",
      "9           10       7      73     127       1      21      19      10   \n",
      "10           6       4      61      39       1      45       8       1   \n",
      "11           6       2      61      35       1       5      50       1   \n",
      "12          11      11      61      97       1       5      31       1   \n",
      "13           7       1      28     137       1      37      11       5   \n",
      "14           8       7      61     137       1      34      12       1   \n",
      "15           8      11      61      95       1      35      65       3   \n",
      "16           6       2      61      90       1      31       1       1   \n",
      "17           7       7      73      55       1       1      19       6   \n",
      "18           6       4      61      97       1      48      10       6   \n",
      "19          11      11      61      71       5      12      65       1   \n",
      "20          11      11      61      97       3       6      31       1   \n",
      "21          12      11      61      35       3      42      25       5   \n",
      "22          11       9      61     132       1      45      31       6   \n",
      "23           6       2      61      97       9      30      65       1   \n",
      "24           6       1      61      72       1      32      32       1   \n",
      "25           6       2      61     132       5      48      37       1   \n",
      "26           7       4      61     137       1      38       8       5   \n",
      "27           6       2      61      97       5       5      65       1   \n",
      "28           9       6      61     132       7      40      31       3   \n",
      "29          10       6      28     132       1      21      14       1   \n",
      "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "313834      11      11      61     132       1      45      31       1   \n",
      "313835      12       3      61     127       3      14      25       1   \n",
      "313836       7       2      18     142       1      34      37       1   \n",
      "313837      11      11      83       3       1      45      63      10   \n",
      "313838       6       2      61      72       1      48      50       1   \n",
      "313839       9       6      61     132       1      42      31       5   \n",
      "313840       6       4      61      90       1       5      46       3   \n",
      "313841       7       4      61      90       1       5      40       5   \n",
      "313842       9       6      61     127       1      49      19       3   \n",
      "313843       8       2      13      93       1      10      50       1   \n",
      "313844       6       2      61      97       1      34      31      12   \n",
      "313845      10      11      28     137       5      45      12       1   \n",
      "313846      11      11      61      72       1      27      50       6   \n",
      "313847       6       4      61      88       1      45      41       1   \n",
      "313848      11      11      11     132       1       5      31       1   \n",
      "313849       6       2      61      90       1      45       9       1   \n",
      "313850       9      11      61      90       7      34      30       1   \n",
      "313851       5       4      61     137      11       9       8       1   \n",
      "313852      10      11      61      68       1       3      65       1   \n",
      "313853       7       4      61      23       1       3      33       5   \n",
      "313854       5       4      61      29       1       5       8       1   \n",
      "313855       9       6      61      72       7      14      50       1   \n",
      "313856       8       4      61     142       1      10       8       1   \n",
      "313857      10       1      11     142       5      39      32       1   \n",
      "313858       7       2      61      90       1      39      62       3   \n",
      "313859       6       4      61      90       3      35       8       1   \n",
      "313860      10      11      61     117       1      48      62      10   \n",
      "313861       8       7      61      68       1       5      65       1   \n",
      "313862      11      11      11     132       1      11      31       5   \n",
      "313863       7       2      28     142       1      32      32       1   \n",
      "\n",
      "        cat115  cat116  \n",
      "0           15     314  \n",
      "1           15     120  \n",
      "2            9     193  \n",
      "3           15     114  \n",
      "4           11      89  \n",
      "5           11     114  \n",
      "6           11     114  \n",
      "7           16     327  \n",
      "8           17     239  \n",
      "9           15     337  \n",
      "10          11     201  \n",
      "11          11     219  \n",
      "12          15     114  \n",
      "13          11     107  \n",
      "14          16     354  \n",
      "15          12     123  \n",
      "16          10     114  \n",
      "17          15     317  \n",
      "18          11     225  \n",
      "19          18     218  \n",
      "20          15     114  \n",
      "21          16     185  \n",
      "22          14      77  \n",
      "23          11     120  \n",
      "24           9     232  \n",
      "25          11     220  \n",
      "26          11     201  \n",
      "27          11     114  \n",
      "28          14     219  \n",
      "29          13     215  \n",
      "...        ...     ...  \n",
      "313834      14     219  \n",
      "313835      18     309  \n",
      "313836      11     115  \n",
      "313837      16     193  \n",
      "313838      11     120  \n",
      "313839      14     219  \n",
      "313840      10     222  \n",
      "313841      10     191  \n",
      "313842      13     215  \n",
      "313843      12      96  \n",
      "313844      11     114  \n",
      "313845      15     218  \n",
      "313846      17     336  \n",
      "313847      10     219  \n",
      "313848      15     114  \n",
      "313849      11     225  \n",
      "313850      14     225  \n",
      "313851      10     318  \n",
      "313852      15     201  \n",
      "313853      12     219  \n",
      "313854      10     318  \n",
      "313855      15     219  \n",
      "313856      11     201  \n",
      "313857      13      80  \n",
      "313858      12     120  \n",
      "313859      11     201  \n",
      "313860      15     120  \n",
      "313861      16     337  \n",
      "313862      15     114  \n",
      "313863      12      96  \n",
      "\n",
      "[313864 rows x 116 columns]\n",
      "('\\nMedian Loss:', 2115.5699999999997)\n",
      "('Mean Loss:', 3037.3376856699833)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy.stats import skew, boxcox\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "import os\n",
    "os.chdir(\"/home/udit/ipython/notebook/all/input\")\n",
    "\n",
    "shift = 200\n",
    "COMB_FEATURE = 'cat80,cat87,cat57,cat12,cat79,cat10,cat7,cat89,cat2,cat72,' \\\n",
    "               'cat81,cat11,cat1,cat13,cat9,cat3,cat16,cat90,cat23,cat36,' \\\n",
    "               'cat73,cat103,cat40,cat28,cat111,cat6,cat76,cat50,cat5,' \\\n",
    "               'cat4,cat14,cat38,cat24,cat82,cat25'.split(',')\n",
    "\n",
    "def encode(charcode):\n",
    "    r = 0\n",
    "    ln = len(str(charcode))\n",
    "    for i in range(ln):\n",
    "        r += (ord(str(charcode)[i]) - ord('A') + 1) * 26 ** (ln - i - 1)\n",
    "    return r\n",
    "\n",
    "fair_constant = 0.7\n",
    "def fair_obj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    x = (preds - labels)\n",
    "    den = abs(x) + fair_constant\n",
    "    grad = fair_constant * x / (den)\n",
    "    hess = fair_constant * fair_constant / (den * den)\n",
    "    return grad, hess\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y)-shift,\n",
    "                                      np.exp(yhat)-shift)\n",
    "def mungeskewed(train, test, numeric_feats):\n",
    "    ntrain = train.shape[0]\n",
    "    test['loss'] = 0\n",
    "    train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "    skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "    skewed_feats = skewed_feats[skewed_feats > 0.25]\n",
    "    skewed_feats = skewed_feats.index\n",
    "\n",
    "    for feats in skewed_feats:\n",
    "        train_test[feats] = train_test[feats] + 1\n",
    "        train_test[feats], lam = boxcox(train_test[feats])\n",
    "    return train_test, ntrain\n",
    "\n",
    "\n",
    "\n",
    "print('\\nStarted')\n",
    "directory = '../input/'\n",
    "train = pd.read_csv(directory + 'train.csv')\n",
    "test = pd.read_csv(directory + 'test.csv')\n",
    "\n",
    "numeric_feats = [x for x in train.columns[1:-1] if 'cont' in x]\n",
    "categorical_feats = [x for x in train.columns[1:-1] if 'cat' in x]\n",
    "train_test, ntrain = mungeskewed(train, test, numeric_feats)\n",
    "\n",
    "# taken from Vladimir's script (https://www.kaggle.com/iglovikov/allstate-claims-severity/xgb-1114)\n",
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = remove_train.union(remove_test)\n",
    "\n",
    "\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "\n",
    "        train_test[column] = train_test[column].apply(lambda x: filter_cat(x), 1)\n",
    "\n",
    "# taken from Ali's script (https://www.kaggle.com/aliajouz/allstate-claims-severity/singel-model-lb-1117)\n",
    "train_test[\"cont1\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont1\"]))\n",
    "train_test[\"cont4\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont4\"]))\n",
    "train_test[\"cont5\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont5\"]))\n",
    "train_test[\"cont8\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont8\"]))\n",
    "train_test[\"cont10\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont10\"]))\n",
    "train_test[\"cont11\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont11\"]))\n",
    "train_test[\"cont12\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont12\"]))\n",
    "\n",
    "train_test[\"cont6\"] = np.log(preprocessing.minmax_scale(train_test[\"cont6\"]) + 0000.1)\n",
    "train_test[\"cont7\"] = np.log(preprocessing.minmax_scale(train_test[\"cont7\"]) + 0000.1)\n",
    "train_test[\"cont9\"] = np.log(preprocessing.minmax_scale(train_test[\"cont9\"]) + 0000.1)\n",
    "train_test[\"cont13\"] = np.log(preprocessing.minmax_scale(train_test[\"cont13\"]) + 0000.1)\n",
    "train_test[\"cont14\"] = (np.maximum(train_test[\"cont14\"] - 0.179722, 0) / 0.665122) ** 0.25\n",
    "\n",
    "\n",
    "for comb in itertools.combinations(COMB_FEATURE, 2):\n",
    "        feat = comb[0] + \"_\" + comb[1]\n",
    "        train_test[feat] = train_test[comb[0]] + train_test[comb[1]]\n",
    "        train_test[feat] = train_test[feat].apply(encode)\n",
    "        print('Combining Columns:', feat)\n",
    "        \n",
    "print('')\n",
    "for col in categorical_feats:\n",
    "    print('Analyzing Column:', col)\n",
    "    train_test[col] = train_test[col].apply(encode)\n",
    "\n",
    "print(train_test[categorical_feats])\n",
    "\n",
    "ss = StandardScaler()\n",
    "train_test[numeric_feats] = \\\n",
    "    ss.fit_transform(train_test[numeric_feats].values)\n",
    "\n",
    "train = train_test.iloc[:ntrain, :].copy()\n",
    "test = train_test.iloc[ntrain:, :].copy()\n",
    "\n",
    "print('\\nMedian Loss:', train.loss.median())\n",
    "print('Mean Loss:', train.loss.mean())\n",
    "\n",
    "ids = pd.read_csv('../input/test.csv')['id']\n",
    "#train_y = np.log(train['loss'] + shift)\n",
    "#train_x = train.drop(['loss','id'], axis=1)\n",
    "#test_x = test.drop(['loss','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = np.log(train['loss'] + shift)\n",
    "train_x = train.drop(['loss','id'], axis=1)\n",
    "test_x = test.drop(['loss','id'], axis=1)\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg = Ridge(alpha=0.1,normalize=True,solver ='svd',random_state =500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridgereg.fit(train_x,train_y)\n",
    "y_pred = ridgereg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.45429293,  7.67715292,  9.45304118, ...,  7.74219386,\n",
       "        7.24243787,  8.14787073])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COMB_FEATURE.extend(numeric_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = train['loss'] >60000\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "train_x = train.drop(['loss','id'], axis=1)\n",
    "test_x = test.drop(['loss','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "features=COMB_FEATURE\n",
    "foundvalues=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88104.5366667\n",
      "('ids to consider', array([134574]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=60000\n",
    "train_y = train['loss'] >=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[train['loss'] >outliervalue,'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "outliers=dd.id[dd.pred==1].values\n",
    "foundvalues.append(outliers)\n",
    "print('ids to consider',outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54750.454\n",
      "('ids to consider', array([134574, 340105]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=50000\n",
    "train_y = train['loss']>=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print( train.loc[(train['loss'] > outliervalue) & (train['loss'] <60000) ,'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47512.7025\n",
      "('ids to consider', array([134574, 340105]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=45000\n",
    "train_y = train['loss']>=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <50000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42562.72875\n",
      "('ids to consider', array([134574, 340105]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=40000\n",
    "train_y = train['loss'] >=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <45000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37229.7827273\n",
      "('ids to consider', array([  5062, 134574, 167575, 244173, 272417, 340105]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=35000\n",
    "train_y = train['loss'] >=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <40000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31992.4851724\n",
      "('ids to consider', array([  5062, 134574, 167575, 244173, 272417, 340105, 346331]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=30000\n",
    "train_y = train['loss'] >=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <35000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   15.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26871.6395833\n",
      "('ids to consider', array([  5062, 134574, 272417, 316492, 340105, 346331, 390735]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=25000\n",
    "train_y = train['loss'] >outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <30000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   15.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21957.6616129\n",
      "('ids to consider', array([ 13320,  67099, 100794, 120786, 134574, 148845, 173206, 221755,\n",
      "       222683, 247475, 272417, 340105, 346237, 346331, 369669, 536291]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=20000\n",
    "train_y = train['loss'] >=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <25000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   15.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18920.7969136\n",
      "('ids to consider', array([ 13320,  54348,  63760,  67099,  76074,  91026, 100794, 120786,\n",
      "       134574, 148845, 173206, 198598, 201541, 221755, 222683, 247475,\n",
      "       248401, 255243, 270014, 272417, 316492, 317189, 320790, 340105,\n",
      "       346331, 369669, 390735, 399937, 516196, 536291, 537199, 537393,\n",
      "       583966]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=18000\n",
    "train_y = train['loss'] >=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <20000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   18.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16866.2985185\n",
      "('ids to consider', array([  5062,  13320,  43761,  50594,  52607,  54348,  63760,  67099,\n",
      "        76074,  91026, 100794, 108707, 117377, 120499, 120786, 134574,\n",
      "       135844, 147997, 148845, 177797, 179718, 198509, 201541, 221755,\n",
      "       222683, 236220, 242548, 243938, 244173, 246138, 247475, 247717,\n",
      "       248401, 255243, 270014, 272417, 310350, 313585, 316492, 317189,\n",
      "       320790, 330451, 339415, 340105, 341360, 341757, 346331, 368866,\n",
      "       369669, 378956, 390735, 399269, 399937, 407129, 412986, 415786,\n",
      "       428558, 431351, 437160, 460474, 461160, 501940, 516196, 527816,\n",
      "       536291, 536587, 537393, 545235, 572250, 577023, 578946, 586360]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=16000\n",
    "train_y = train['loss'] >=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <18000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   15.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15477.2936789\n",
      "('ids to consider', array([  5062,  13320,  22361,  27363,  43761,  50594,  50726,  52607,\n",
      "        54348,  55510,  63760,  67099,  71409,  76074,  91026, 100794,\n",
      "       104009, 108707, 113000, 120499, 120786, 127331, 134574, 135844,\n",
      "       147997, 148845, 149299, 156677, 159346, 160838, 165557, 177797,\n",
      "       193082, 198509, 198598, 201541, 208075, 215364, 221755, 222683,\n",
      "       238518, 242548, 243938, 246138, 247717, 247734, 248401, 254629,\n",
      "       255243, 261665, 267500, 270014, 275432, 281241, 281983, 295527,\n",
      "       309706, 316492, 317189, 320790, 330451, 332506, 340105, 341360,\n",
      "       341757, 346237, 346331, 346956, 367972, 368866, 369669, 378956,\n",
      "       383082, 384581, 386468, 390735, 399269, 399937, 400255, 407129,\n",
      "       412986, 414520, 415786, 426802, 428558, 431351, 431668, 437160,\n",
      "       460474, 461160, 462125, 466920, 471024, 480967, 488678, 501940,\n",
      "       502919, 516196, 520167, 527816, 536291, 536587, 537199, 537393,\n",
      "       549891, 569316, 572250, 575000, 577023, 578946, 586360]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=15000\n",
    "train_y = train['loss'] >=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <16000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   16.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13916.4069201\n",
      "('ids to consider', array([  2458,   4705,   5062,   6385,   7210,   8410,  11748,  12376,\n",
      "        13320,  14835,  17790,  21439,  22361,  24452,  27363,  27585,\n",
      "        33069,  36221,  36612,  42126,  43761,  46085,  49760,  50594,\n",
      "        50678,  50726,  50985,  52607,  54348,  55510,  60107,  60908,\n",
      "        63760,  64463,  64770,  67099,  69260,  71409,  71989,  76074,\n",
      "        81573,  84703,  87768,  91026,  93666, 100794, 101076, 102707,\n",
      "       104009, 108642, 108707, 113000, 114583, 117322, 117377, 120499,\n",
      "       120786, 126892, 127331, 130018, 130708, 134574, 135844, 137607,\n",
      "       138307, 143787, 145094, 147997, 148845, 149299, 150384, 152520,\n",
      "       155923, 156677, 158396, 159346, 165557, 168334, 170184, 176171,\n",
      "       177797, 178636, 179718, 189333, 190045, 198509, 198598, 201541,\n",
      "       204090, 208075, 208309, 210178, 211283, 215364, 215380, 215543,\n",
      "       221755, 222683, 225066, 228101, 233718, 236220, 238518, 240039,\n",
      "       242548, 242834, 242914, 243134, 243593, 243938, 244173, 246138,\n",
      "       247717, 248401, 254629, 255243, 257132, 257903, 260677, 260978,\n",
      "       261665, 267500, 267952, 270014, 270087, 271417, 272417, 275432,\n",
      "       278910, 281241, 281822, 281983, 283850, 284203, 286168, 291215,\n",
      "       293163, 293294, 295527, 310350, 316261, 316492, 317189, 317695,\n",
      "       318086, 320790, 322704, 324370, 326052, 326973, 328725, 330451,\n",
      "       331377, 332506, 334400, 338910, 340105, 341360, 341757, 343141,\n",
      "       346237, 346331, 346763, 348780, 352558, 355199, 358369, 365145,\n",
      "       367972, 368866, 369669, 369987, 373864, 374466, 377816, 378956,\n",
      "       380884, 381381, 383082, 384581, 386468, 388150, 389601, 390259,\n",
      "       390735, 395062, 397163, 399269, 399937, 400255, 403631, 406780,\n",
      "       407129, 407563, 411864, 412986, 414520, 415234, 415786, 419165,\n",
      "       419662, 421276, 424545, 426802, 428558, 431273, 431351, 431668,\n",
      "       435516, 437160, 438254, 444952, 449829, 450348, 453925, 458524,\n",
      "       458676, 460474, 462125, 464672, 466920, 471024, 475907, 480344,\n",
      "       480967, 484666, 486690, 488678, 492895, 497060, 498666, 498891,\n",
      "       501940, 502919, 503576, 506997, 516096, 516196, 517960, 519653,\n",
      "       520167, 527763, 527816, 530748, 533978, 536291, 536587, 537199,\n",
      "       537435, 538885, 545189, 545235, 549002, 556468, 556538, 563475,\n",
      "       568387, 569316, 570301, 571880, 572250, 575000, 575493, 577023,\n",
      "       578946, 583966, 586216, 586360]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=13000\n",
    "train_y = train['loss'] >=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <15000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   15.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12478.8896287\n",
      "('ids to consider', array([  2280,   2458,   4705,   5062,   7210,   8410,   9405,  10627,\n",
      "        11729,  11748,  12201,  12376,  13320,  14835,  16238,  17790,\n",
      "        19248,  21439,  22361,  23935,  24318,  24452,  27363,  27585,\n",
      "        33069,  36221,  36612,  42126,  43761,  45448,  46085,  47114,\n",
      "        47587,  48705,  50594,  50678,  50726,  50985,  51432,  52607,\n",
      "        54348,  55510,  55591,  60107,  60908,  63760,  64463,  64654,\n",
      "        64770,  65599,  67099,  68901,  69260,  70843,  71409,  71989,\n",
      "        72222,  73026,  76074,  77594,  79506,  80856,  81573,  81937,\n",
      "        82236,  82719,  84703,  87768,  91026,  92670,  93666,  94328,\n",
      "        96280, 100794, 101076, 102707, 103259, 104009, 108066, 108642,\n",
      "       108707, 113000, 114583, 116620, 117322, 117377, 120499, 120747,\n",
      "       120786, 122917, 124891, 126892, 127331, 130018, 130708, 134574,\n",
      "       135844, 137607, 137749, 138307, 138849, 143787, 144469, 145094,\n",
      "       146530, 147997, 148845, 149173, 149299, 150384, 152520, 155923,\n",
      "       156677, 158396, 159346, 159853, 160838, 165557, 168334, 168384,\n",
      "       169470, 174484, 175211, 176171, 177797, 178636, 179718, 180004,\n",
      "       181715, 181974, 186176, 188833, 189333, 190045, 193082, 197118,\n",
      "       197488, 197975, 198509, 198598, 200296, 201541, 202888, 204090,\n",
      "       205378, 207188, 208075, 208309, 210178, 215364, 215380, 215543,\n",
      "       215743, 217257, 220324, 221755, 222683, 225066, 228101, 233536,\n",
      "       233718, 234841, 235500, 236220, 238518, 238753, 240039, 242548,\n",
      "       242834, 242914, 243134, 243593, 243938, 244173, 246138, 247717,\n",
      "       247925, 248401, 253401, 254629, 255216, 255243, 257132, 257903,\n",
      "       259829, 260102, 260677, 260978, 261209, 261665, 267114, 267500,\n",
      "       267952, 268142, 270014, 270087, 271417, 272417, 275432, 275799,\n",
      "       278910, 281241, 281822, 281983, 283850, 284203, 284951, 286030,\n",
      "       286168, 291215, 291339, 293163, 293294, 295527, 300009, 302071,\n",
      "       303749, 304492, 306601, 310350, 314370, 316261, 316492, 317164,\n",
      "       317189, 317695, 318086, 319746, 320790, 322704, 323663, 324370,\n",
      "       326052, 326973, 328725, 330451, 331219, 331377, 332221, 332506,\n",
      "       334400, 338408, 338910, 339709, 340105, 340685, 341360, 341655,\n",
      "       341757, 343141, 344861, 344904, 346237, 346331, 346763, 348780,\n",
      "       352558, 352685, 354754, 355199, 358369, 360932, 362906, 365145,\n",
      "       366489, 367333, 367972, 368150, 368866, 369669, 369987, 371330,\n",
      "       373864, 373992, 374466, 376670, 377537, 377816, 378652, 378956,\n",
      "       380884, 381381, 383082, 383865, 384581, 385083, 386468, 386942,\n",
      "       388150, 389601, 390259, 390735, 391406, 391418, 392631, 395062,\n",
      "       397163, 397972, 399269, 399664, 399937, 400255, 400641, 402500,\n",
      "       403631, 404094, 404506, 406780, 407511, 407982, 411864, 412382,\n",
      "       412986, 414520, 415234, 415260, 415786, 417777, 419165, 419662,\n",
      "       421276, 422722, 422739, 424545, 426802, 427670, 428558, 431273,\n",
      "       431351, 431668, 431820, 434415, 435516, 437160, 438254, 440914,\n",
      "       444675, 444952, 445314, 446387, 449829, 450335, 450348, 453507,\n",
      "       453925, 458524, 458676, 460474, 461160, 462125, 463046, 463463,\n",
      "       464672, 466920, 469161, 471024, 471470, 474629, 475907, 479773,\n",
      "       480344, 480967, 483276, 484666, 486690, 488678, 490787, 492895,\n",
      "       492964, 493728, 495580, 496923, 497060, 498666, 498891, 500352,\n",
      "       501380, 501940, 502919, 503576, 504770, 506997, 516096, 516196,\n",
      "       517960, 519653, 520048, 520167, 525267, 527469, 527763, 527816,\n",
      "       529889, 530748, 531402, 531876, 532887, 533978, 534872, 536291,\n",
      "       536587, 537199, 537393, 537435, 538885, 544689, 545189, 545235,\n",
      "       545394, 547692, 549002, 556468, 556538, 563475, 564257, 564594,\n",
      "       565004, 568387, 569316, 569815, 570301, 571880, 572250, 575000,\n",
      "       575456, 575493, 576844, 577023, 578946, 579339, 582387, 583966,\n",
      "       586216, 586360]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=12000\n",
    "train_y = train['loss'] >=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <13000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10903.4878405\n",
      "('ids to consider', array([   394,   1080,   2280, ..., 586216, 586360, 586395]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=10000\n",
    "train_y = train['loss'] >=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] >outliervalue) & (train['loss'] <12000),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.88666666667\n",
      "('ids to consider', array([334750]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=15\n",
    "train_y = train['loss'] <=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] <outliervalue),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.7861538462\n",
      "('ids to consider', array([ 58499, 395535]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=60\n",
    "train_y = train['loss'] <=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] <outliervalue)&(train['loss'] >15),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   15.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541.801244207\n",
      "('ids to consider', array([ 19379,  75007, 186199, 220699, 324309, 367135, 378411, 382233,\n",
      "       396037, 408842, 424707, 509320, 549979]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "outliervalue=700\n",
    "train_y = train['loss'] <=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] < outliervalue)&(train['loss'] >60),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outliervalue=100\n",
    "train_y = train['loss'] <=outliervalue\n",
    "train_y=pd.factorize(train_y)[0]\n",
    "model = RandomForestClassifier(n_estimators = 50, n_jobs = -1,random_state =50, max_features = 0.8, max_depth= 8,oob_score =True,verbose =1)\n",
    "model.fit(train_x[features], train_y)\n",
    "preds = model.predict(test_x[features])\n",
    "print(train.loc[(train['loss'] <outliervalue)&(train['loss'] >60),'loss'].mean())\n",
    "dd=pd.DataFrame({\"id\":test.id,'pred':preds})\n",
    "print('ids to consider',dd.id[dd.pred==1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "udit\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "cv_sum = 0\n",
    "early_stopping = 100\n",
    "fpred = []\n",
    "xgb_rounds = []\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(train.shape[0], n_folds=n_folds)\n",
    "for i, (train_index, test_index) in enumerate(kf):\n",
    "    print('\\n Fold %d' % (i+1))\n",
    "    X_train, X_val = train_x.iloc[train_index], train_x.iloc[test_index]\n",
    "    y_train, y_val = train_y.iloc[train_index], train_y.iloc[test_index]\n",
    "\n",
    "    rand_state = 2016\n",
    "\n",
    "    params = {\n",
    "        'seed': 0,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'silent': 1,\n",
    "        'subsample': 0.7,\n",
    "        'learning_rate': 0.03,\n",
    "        'objective': 'reg:linear',\n",
    "        'max_depth': 12,\n",
    "        'min_child_weight': 100,\n",
    "        'booster': 'gbtree'}\n",
    "\n",
    "    d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    d_valid = xgb.DMatrix(X_val, label=y_val)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'eval')]\n",
    "\n",
    "    clf = xgb.train(params,\n",
    "                    d_train,\n",
    "                    100000,\n",
    "                    watchlist,\n",
    "                    early_stopping_rounds=50,\n",
    "                    obj=fair_obj,\n",
    "                    feval=xg_eval_mae)\n",
    "\n",
    "    xgb_rounds.append(clf.best_iteration)\n",
    "    scores_val = clf.predict(d_valid, ntree_limit=clf.best_ntree_limit)\n",
    "    cv_score = mean_absolute_error(np.exp(y_val), np.exp(scores_val))\n",
    "    print('eval-MAE: %.6f' % cv_score)\n",
    "    y_pred = np.exp(clf.predict(d_test, ntree_limit=clf.best_ntree_limit)) - shift\n",
    "\n",
    "    if i > 0:\n",
    "        fpred = pred + y_pred\n",
    "    else:\n",
    "        fpred = y_pred\n",
    "    pred = fpred\n",
    "    cv_sum = cv_sum + cv_score\n",
    "\n",
    "mpred = pred / n_folds\n",
    "score = cv_sum / n_folds\n",
    "print('Average eval-MAE: %.6f' % score)\n",
    "n_rounds = int(np.mean(xgb_rounds))\n",
    "\n",
    "print(\"Writing results\")\n",
    "result = pd.DataFrame(mpred, columns=['loss'])\n",
    "result[\"id\"] = ids\n",
    "result = result.set_index(\"id\")\n",
    "print(\"%d-fold average prediction:\" % n_folds)\n",
    "\n",
    "now = datetime.now()\n",
    "score = str(round((cv_sum / n_folds), 6))\n",
    "sub_file = 'xgb_6_submission_5fold-average-xgb_fairobj_' + str(score) + '_' + str(\n",
    "    now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "print(\"Writing submission: %s\" % sub_file)\n",
    "result.to_csv(sub_file, index=True, index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
