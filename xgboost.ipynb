{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Vladimir Iglovikov'\n",
    "import os\n",
    "os.chdir(\"/home/udit/ipython/notebook/all/input\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy import stats\n",
    "train = pd.read_csv('../input/train.csv.zip')\n",
    "test = pd.read_csv('../input/test.csv.zip')\n",
    "test['loss'] = np.nan\n",
    "joined = pd.concat([train, test])\n",
    "\n",
    "# function - absolute of mean shifted data (which will be later used in function transformer)\n",
    "def abs_mean_shift(data):\n",
    "    return np.abs(data - np.mean(data))\n",
    "\n",
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    con = 2\n",
    "    x =preds-labels\n",
    "    grad =con*x / (np.abs(x)+con)\n",
    "    hess =con**2 / (np.abs(x)+con)**2\n",
    "    return grad, hess \n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))\n",
    "\n",
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = remove_train.union(remove_test)\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "        joined[column] = joined[column].apply(lambda x: filter_cat(x), 1)\n",
    "    joined[column] = pd.factorize(joined[column].values, sort=True)[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def ceate_feature_map(features,featuremap_File):\n",
    "    outfile = open(featuremap_File, 'w')\n",
    "    i = 0\n",
    "    for feat in features:\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "        i = i + 1\n",
    "\n",
    "    outfile.close()\n",
    "def plot_feature(bst,featuremap_File):\n",
    "    importance = bst.get_fscore(fmap=featuremap_File)\n",
    "    importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "    df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "    df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "    plt.figure()\n",
    "    df.plot()\n",
    "    df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))\n",
    "    plt.title('XGBoost Feature Importance')\n",
    "    plt.xlabel('relative importance') \n",
    "    return df.sort_values(by='fscore',ascending=False)\n",
    "\n",
    "def train_Val(params,train,target_labels,boosting_rounds=40,print_every_n=10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target_labels, test_size=0.30, random_state=42)\n",
    "    dtrain = xgb.DMatrix(X_train, label =y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label =y_test)\n",
    "    evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "    bst =xgb.train(params,dtrain,num_boost_round=boosting_rounds,evals=evallist,early_stopping_rounds=50,verbose_eval=print_every_n, obj=logregobj, feval=evalerror)\n",
    "    return bst,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly=preprocessing.PolynomialFeatures(2)\n",
    "cat_feature = [n for n in joined.columns if n.startswith('cat')]    \n",
    "cont_feature = [n for n in joined.columns if n.startswith('cont')] \n",
    "\n",
    "poly_features=poly.fit_transform(joined[cont_feature])\n",
    "poly_features=pd.DataFrame(poly_features)\n",
    "poly_features.columns=['polly_'+str(col) for col in poly_features.columns]\n",
    "joined=joined.drop(cont_feature,axis=1)\n",
    "joined=pd.concat([joined,poly_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mae:3182.05\ttrain-mae:3174.35\n",
      "Multiple eval metrics have been passed: 'train-mae' will be used for early stopping.\n",
      "\n",
      "Will train until train-mae hasn't improved in 50 rounds.\n",
      "[10]\teval-mae:1369.16\ttrain-mae:1365.43\n",
      "[20]\teval-mae:497.527\ttrain-mae:495.853\n",
      "[30]\teval-mae:190.85\ttrain-mae:189.905\n",
      "[40]\teval-mae:93.6419\ttrain-mae:92.8421\n",
      "[50]\teval-mae:70.021\ttrain-mae:69.3996\n",
      "[60]\teval-mae:62.5243\ttrain-mae:62.0543\n",
      "[70]\teval-mae:61.0504\ttrain-mae:60.6206\n",
      "[80]\teval-mae:57.9304\ttrain-mae:57.5783\n",
      "[90]\teval-mae:57.0985\ttrain-mae:56.7847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.080712325258993"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train = joined[joined['loss'].notnull()]\n",
    "test = joined[joined['loss'].isnull()]\n",
    "\n",
    "shift = 200\n",
    "y = np.log(train['loss'] + shift)\n",
    "ids = test['id']\n",
    "X = train.drop(['loss', 'id'], 1)\n",
    "X_test = test.drop(['loss', 'id'], 1)\n",
    "\n",
    "RANDOM_STATE = 2016\n",
    "params = {\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.1,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'subsample': 0.8,\n",
    "    'alpha': 1,\n",
    "    'gamma': 1,\n",
    "    'verbose_eval': True,\n",
    "    'seed': RANDOM_STATE\n",
    "}\n",
    "bst,X_test,y_test=train_Val(params,train.values,y,boosting_rounds=100,print_every_n=10)\n",
    "Dtest=xgb.DMatrix(X_test)\n",
    "pred=bst.predict(Dtest)\n",
    "mean_absolute_error(np.expm1(y_test-shift),np.expm1(pred-shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(np.expm1(y_test-shift),np.expm1(pred-shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = joined[joined['loss'].notnull()]\n",
    "test = joined[joined['loss'].isnull()]\n",
    "\n",
    "shift = 200\n",
    "y = np.log(train['loss'] + shift)\n",
    "ids = test['id']\n",
    "X = train.drop(['loss', 'id'], 1)\n",
    "X_test = test.drop(['loss', 'id'], 1)\n",
    "\n",
    "RANDOM_STATE = 2016\n",
    "params = {\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.01,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'subsample': 0.8,\n",
    "    'alpha': 1,\n",
    "    'gamma': 1,\n",
    "    'silent': 1,\n",
    "    'verbose_eval': True,\n",
    "    'seed': RANDOM_STATE\n",
    "}\n",
    "\n",
    "xgtrain = xgb.DMatrix(X, label=y)\n",
    "xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "model = xgb.train(params, xgtrain, int(2012 / 0.9), feval=evalerror)\n",
    "\n",
    "prediction = np.exp(model.predict(xgtest)) - shift\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['loss'] = prediction\n",
    "submission['id'] = ids\n",
    "submission.to_csv('sub_v_6.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 16, 6\n",
    "featuremap_File=\"fet.map\"\n",
    "ceate_feature_map(feature,featuremap_File)\n",
    "features_imp=plot_feature(bst,featuremap_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
