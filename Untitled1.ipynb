{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 130),(125546, 130)\n",
      "{'eval_metric': 'mae', 'seed': 1, 'nrounds': 493, 'booster': 'gbtree', 'colsample_bytree': 0.3085, 'min_child_weight': 4.2922, 'subsample': 0.993, 'eta': 0.1, 'objective': 'reg:linear', 'max_depth': 7, 'gamma': 0.529}\n",
      "XGB-CV: 0.415275143663\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Based on Faron' script \n",
    "https://www.kaggle.com/mmueller/allstate-claims-severity/stacking-starter/run/390867\n",
    "\"\"\"\n",
    "## loading packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "import gc\n",
    "\n",
    "import os\n",
    "os.chdir(\"/home/udit/ipython/notebook/all/input\")\n",
    "\n",
    "### setup\n",
    "ID = 'id'\n",
    "TARGET = 'loss'\n",
    "NFOLDS = 5\n",
    "SEED = 1\n",
    "NROWS = None\n",
    "DATA_DIR = \"../input\"\n",
    "OUT_DIR =\"../input\"\n",
    "\n",
    "\n",
    "### reading data \n",
    "TRAIN_FILE = \"{0}/train.csv\".format(DATA_DIR)\n",
    "TEST_FILE = \"{0}/test.csv\".format(DATA_DIR)\n",
    "SUBMISSION_FILE = \"{0}/sample_submission.csv\".format(DATA_DIR)\n",
    "\n",
    "train = pd.read_csv(TRAIN_FILE, nrows=NROWS)\n",
    "test = pd.read_csv(TEST_FILE, nrows=NROWS)\n",
    "\n",
    "\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = np.log(train[TARGET]).ravel()\n",
    "id_train= train[ID]\n",
    "id_test= test[ID]\n",
    "\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "\n",
    "### remeber the order\n",
    "train_test[ID]=pd.Categorical(train_test[ID], train_test[ID].values.tolist())\n",
    "\n",
    "### factorize\n",
    "cats = [feat for feat in train.columns if 'cat' in feat]\n",
    "for cat in cats:\n",
    "    sorting_list=np.unique(sorted(train_test[cat],key=lambda x:(str.lower(x),x)))\n",
    "    train_test[cat]=pd.Categorical(train_test[cat], sorting_list)\n",
    "    train_test=train_test.sort_values(cat)\n",
    "    train_test[cat] = pd.factorize(train_test[cat], sort=True)[0]\n",
    "\n",
    "### reorder \n",
    "train_test=train_test.sort_values(ID)\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "#### preprocessing\n",
    "train_test[\"cont1\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont1\"]))\n",
    "train_test[\"cont4\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont4\"]))\n",
    "train_test[\"cont5\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont5\"]))\n",
    "train_test[\"cont8\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont8\"]))\n",
    "train_test[\"cont10\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont10\"]))\n",
    "train_test[\"cont11\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont11\"]))\n",
    "train_test[\"cont12\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont12\"]))\n",
    "\n",
    "train_test[\"cont6\"] = np.log(preprocessing.minmax_scale(train_test[\"cont6\"])+0000.1)\n",
    "train_test[\"cont7\"] = np.log(preprocessing.minmax_scale(train_test[\"cont7\"])+0000.1)\n",
    "train_test[\"cont9\"] = np.log(preprocessing.minmax_scale(train_test[\"cont9\"])+0000.1)\n",
    "train_test[\"cont13\"] = np.log(preprocessing.minmax_scale(train_test[\"cont13\"])+0000.1)\n",
    "train_test[\"cont14\"]=(np.maximum(train_test[\"cont14\"]-0.179722,0)/0.665122)**0.25\n",
    "\n",
    "\n",
    "### define x_train, x_test\n",
    "train_test.drop([ID, TARGET], axis=1, inplace=True)\n",
    "x_train = np.array(train_test.iloc[:ntrain,:])\n",
    "x_test = np.array(train_test.iloc[ntrain:,:])\n",
    "print(\"{},{}\".format(x_train.shape, x_test.shape))\n",
    "\n",
    "\n",
    "\n",
    "### setup training functions\n",
    "\n",
    "kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "\n",
    "\n",
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))\n",
    "\n",
    "\n",
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "    \n",
    "    \n",
    "#### xgb\n",
    "xgb_params = {\n",
    "    'seed': 1,\n",
    "    'colsample_bytree': 0.3085,\n",
    "    'subsample': 0.9930,\n",
    "    'eta': 0.1,\n",
    "    'gamma': 0.5290,\n",
    "    'booster' :  'gbtree',    \n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 4.2922,\n",
    "    'eval_metric': 'mae'\n",
    "}\n",
    "\n",
    "\n",
    "# LB 1117.65579\n",
    "#xgb_params['nrounds']=xgb2_rounds\n",
    "xgb_params['nrounds']=493\n",
    "print(xgb_params)\n",
    "\n",
    "xgb_model = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "xgb_oof_train, xgb_oof_test = get_oof(xgb_model)\n",
    "print(\"XGB-CV: {}\".format(mean_absolute_error(y_train, xgb_oof_train)))\n",
    "\n",
    "xgb_test = pd.DataFrame(np.exp(xgb_oof_test), columns=[TARGET])\n",
    "xgb_test[ID] = id_test\n",
    "xgb_test.to_csv('xgb_test_Faron.csv', index=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
